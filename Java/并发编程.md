## ThreadLocal

ThreadLocal实现多线程下访问变量安全，是因为每个线程访问时会在对应线程内生成一个ThreadLocalMap，并生成Entry数组，每个元素以ThreadLocal为key，访问的值为value；

ThreadLocal作为key（变为弱引用Entry的构造函数super（current ThreadLocal））；

引发内存泄露原因分析：（使用remove删除value）
- 强引用（不会回收）
- 软引用（如果内存够不回收）
- 弱引用（发生GC一定回收）
- 虚引用

注：wait, notify和notifyAll不是线程Thread的方法，而是Object方法;wait会释放持有的锁，而notify和notifyAll需要等代码执行完才释放持有的锁；

yield让出cpu执行，不释放锁；
sleep不会释放锁，让出cpu；
wait释放锁，让出cpu，唤醒后会竞争锁；
notify释放锁，必须代码块锁执行完才释放，所以一般放到代码块锁的最后一行，保证锁释放；

## 多线程

### Semaphore 信号量

信号量做流量控制，使用时注意使用两个信号量进行控制（空位防止问题），单个信号量会导致控制时可以随意增加，失去控制效果；AQS锁实现；

### Callable, Future, FutureTask

多线程实现最常用的是实现Runnable接口的run方法，但run方法无返回值，而Callable接口的实现call方法需要有返回值，可以满足多线程需要返回值的技术要求;

而Callable需要使用FutureTask包装后使用Thread执行；


### CAS（Compare And Swap）原子操作

CAS就是无限循环，比较交换值；

乐观锁（不拿锁，认为别人不会去更新）和悲观锁（先拿锁）

JDK的CAS机制对应的是无锁化编程；
CAS原理是利用CAS指令，自旋循环该指令，直至成功； 

CAS问题：
- ABA问题：加版本号解决（变更过程未记录的问题）
- 开销问题：自旋（循环，不断重试）导致性能问题
- 只能保证一个共享变量的原子操作(使用包装类型)

JDK提供的原子操作类：AtomicBoolean, AtomicInteger, AtomicLong, AtomicIntegerArray, AtomicLongArray, AtomicReferenceArray, AtomicReference, AtomicMarkableReference（解决ABA，记录发生过变化）, AtomicStampedReference(解决ABA，记录变过几次), AtomicReferenceFieldUpdater, AtomicIntegerFieldUpdater, AtomicLongFieldUpdater

### 显示锁和AQS

Java中的显式锁主要为Lock接口和其实现类，而Synchronized为隐式锁，自动获取锁和释放锁;

#### AQS（AbstractQueuedSynchronizer）是什么样的？

AQS是一种构建锁和同步器的框架，各种Lock包中的锁以及Seamphore，CountDownLatch都是基于AQS框架；

- AQS内部定义了一个volatile int state(The synchronization state)的变量标识同步状态；当线程调用lock方法时，若state = 0，表示没有线程占用共享变量，线程可以获得锁并将state置为1；若state不为0，表示有线程正在使用共享变量，其他线程加入同步队列中进行等待；

- AQS通过内部类Node构建一个双向链表的同步队列，完成线程获取锁的排队工作，当有线程获取锁失败时，将线程加入同步队列尾部；
  - Node类是访问同步代码的线程的封装，包含线程本身和等待状态waitStatus（有5种【SINGLE= -1阻塞， CANCELLED = 1取消，CONDITION = -2等待唤醒，PROPAGATE = -3传播，0】），另外有prev,next关联前驱和后继节点，方便线程释放锁后快速唤醒下一个等待线程，是一个FIFO过程；
  - Node类有两个常量ShARED（共享）和EXCLUSIVE（独占）表示不同的模式；Seamphore就是shared共享模式，独占模式只能一个线程对数据进行操作，其他线程排队等待；

- AQS通过内部类ConditionObject构建等待队列（可多个），当Condition调用wait方法后，将线程加入等待队列中，调用signal时，将等待对类移动到同步队列中进行锁的竞争；
- AQS和Condition各自维护不同队列，使用Lock和Condition其实是两个队列的互相移动；

#### Lock显示锁
核心方法为lock(), unlock(), tryLock();

Java 8把current包中的锁从Lock换为synchronized；

公平锁和非公平锁（面试必问），公平锁会将申请所得线程放入队列中，按照先进先出的顺序排队获取锁，不会有线程饿死；而非公平锁会在线程进入申请线程时，先插队获取锁，如果成功，则获取锁，否则放入等待队列末尾等待，可以减少线程唤醒的上下文切换的性能开销，故非公平锁性能高于公平锁；

读写锁(读写互斥)，读锁排斥写锁，写锁排斥读锁（读锁被获取后，其他线程可以获取读锁，而写锁被获取后，其他线程等待，无法获取写锁和读锁）；

LockSupport工具：
- 阻塞线程（park）: unpark方法调用，线程中断，虚假调用之一会结束阻塞
- 唤醒线程（unpark）
- 构建同步组件的基础工具

### synchronize加锁

synchronize是由JVM实现的一种互斥同步方式；查看使用synchronize修饰的的代码块编译后的字节码，发现被monitorenter和monitorexit指令；

当虚拟机执行指令到monitorenter时，尝试获取对象的锁，如果对象没有锁定或者当前线程拥有该对象的锁，把锁的计数器+1；执行monitorexit时，将锁的计数器-1；当锁的计数器为0时锁被释放；

synchronize修饰方法时，在方法的访问标记flags中增加ACC_SYNCHRONIZE标记，告诉JVM只是一个同步方法，进入方法前需要获取锁；

synchronize是通过在对象头（mark word, 类型指针）设置标记，达到获取锁和释放锁的目的；

synchronize锁为悲观锁，因为他的并发策略是悲观的：

不管是否会产生竞争，任何的数据操作都必须要加锁，用户态核心态转换，维护锁计数器和检查是否有被阻塞的线程需要被唤醒等操作；

锁升级过程：无锁-》偏向锁-》轻量级锁（自旋锁，自适应自旋）-》重量级锁

锁消除：
是指虚拟机即时编译在运行时，对一些代码要求同步，但对被检测到不可能存在共享数据竞争的锁进行消除。

锁消除的主要判断依据来自于逃逸分析的数据支持，如果判断一段代码中，在堆上的所有数据都不会逃逸出去被其他线程调用，那就可以把他们当做栈上数据对待，认为数据是线程私有，同步加锁无须进行；

锁粗化：

```Java
public static String testLockCoarsenin(String str) {
        StringBuffer sb = new StringBuffer();
            for(int i = 0; i < 100; i++){
          sb.append(str1);
        }
        return sb.toString();
  }
```
append方法需要获取锁，在未优化情况下，循环调用100次，需要获取和释放锁100次，浪费资源；

JVM会检测到这一串操作均是对一个对象进行锁操作，会将锁优化到循环体之外，使得该操作只需要一次锁操作；

相关文章：https://zhuanlan.zhihu.com/p/118634086

理论上，Hotspot虚拟机中，Java对象在内存中存储布局包括三部分：对象头（Object Header），实例数据（Instance Data），对齐填充（Padding）；

对象头包括mark word（8字节）, 类型指针（4字节，指向方法区中的类信息【元数据metaData】），数组长度（4个字节如果对象是数组）;

### 乐观锁实现原理是什么？什么是CAS，有什么特性？

乐观锁就是基于冲突检测的乐观并发策略，先对数据进行操作，如果没有其他线程操作数据，则操作成功；如果共享数据被其他线程征用，则产生冲突，就需要进行后续的补偿措施；这种乐观的并发策略不需要将线程挂起，所以是非阻塞同步；

乐观锁的核心算法就是CAS（Compare and swap，比较交换），涉及到三个操作数【内存值，期望值，新值】，当且仅当期望值和内存值一致时才将内存值修改为新值；

CAS具有原子性，是原子操作，原子性由CPU的硬件指令保证，对应的Java中的native的unsafe方法；

### 乐观锁一定好吗？（潜台词为乐观锁和被关锁比较，乐观锁缺点）

乐观锁相比较与悲观锁，避免了悲观锁独占对象的现象，同时提高了并发性能；

乐观锁缺点：
- 乐观锁只能保证一个共享变量的原子操作，如果多个共享变量，将力不从心，互斥锁可以解决，不管对象多少和对象的颗粒度大小；
- CAS自旋导致性能开销大，如果长时间不成功，会给CPU带来开销；
- ABA问题；

## 可重入锁ReentrantLock以及其他显示锁相关问题

### 与synchronize相比，ReentrantLock实现原理有什么不同？

锁的实现原理基本都是为了达到一个目的：让所有线程都可以看到某种标记；

synchronize通过在对象头中设置标记达到该目的，是一种JVM原生的锁实现方式；

ReentrantLock以及所有基于Lock接口的实现类，都是通过一个volatile修饰的int类型变量state，并保证每个线程都拥有对该变量的可见性和原子性修改，其本质是基于AQS实现；

## synchronized和ReentrantLock的比较异同？

ReentrantLock是Lock实现类，是一种互斥同步锁；

从功能角度，ReentrantLock功能更多比如等待可中断，带超时的锁获取，判断是否有线程在等待锁，可以实现公平锁等；synchronized是一种Jvm原生的锁实现，可以自动获取锁和释放锁，而ReentrantLock不能自动释放锁，需要自己释放锁操作；

## ReentrantLock如何实现可重入性？

ReentrantLock自定义实现Sync同步器(sync实现AQS)，加锁过程使用CAS算法，比较获取锁的线程是否是已经持有锁的线程，如果一致，则重入；（同步状态status要增加）

## JUC(java.util.concurrent)并发包有哪些并发工具？

CountDownLatch, CyclicBarrier, Seamphore等多线程操作的同步结构；还有CurrentHashMap等线程安全的动态数组；还有Executor框架，创建不同类型线程池；

## 如何让线程彼此同步，了解过哪些同步器，介绍一下

JUC的同步器主要有三个：CountDownLatch（倒计数），CyclicBarrier（循环栅栏）和Seamphore（信号量）；

- CountDownLatch: 允许一个或多个线程等待某些操作完成之后在进行后续执行；如模拟并发等，由第三方线程控制减1操作，第三方控制；
- CycliBarrier: 实现让一组线程等待至某个状态之后全部同时执行，而且所有线程释放之后，CyclicBarrier可复用；(任务线程自己控制，且可复用)
- Seamphore: 信号量控制，用于控制同事访问的线程个数通过acquire获取，release释放许可；

注：

CountDownLatch和CycliBarrier具有极高的相似度，都是多线程到达某个状态后再同时执行；但前者无法复用，后者可以复用；前者操作countDown/await, await使线程阻塞，其他位置countDown到0时，等待线程恢复，不关心执行countDown的线程为单个还是多个；而后者操作await，当所有线程调用await后，计数器减1，减到0会全部同时执行，是由线程自己控制且可复用；后者还可以在等待线程全部到达后触发单独操作；

## Java中线程池实现原理？

线程池是一种基于池化思想管理线程的工具；

当线程过多时，由于线程频繁创建销毁，线程之间调度切换，会造成性能开销；线程池维护多个线程，避免处理任务创建销毁线程开销代价，另外避免线程数量膨胀导致过分调度问题；

线程池带来的好处：降低资源消耗：池化技术，降低线程创建销毁造成的损耗；

Java的线程池的核心实现类是ThreadPoolExecutor类；将线程包装为内部的Worker类，存放在HashSet\<Worker\> workers成员变量中，而等待执行的线程放入到BlockingQueue\<Runnable\> workQueue中；

https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html

个人理解：
线程池就是利用池化思想，创建并维护一些线程在池中，避免线程创建销毁带来的性能开销；
Java线程池是生产者-消费者模式，通过阻塞队列workQueue实现；阻塞队列缓存任务，工作线程从阻塞队列中获取任务；

线程池的四种任务拒绝策略：

- AbortPolicy: 丢弃任务并抛出RejectedExecutionException；（默认）
- DiscardPolicy: 丢弃任务，不抛出异常；
- DiscardOldestPolicy: 丢弃队列最前面的任务，然后重新尝试执行新任务（重复此过程）；
- CallerRunsPolicy: 调用线程处理该任务；

线程池相关接口以及实现关系：

- Executor（顶级接口）：execute方法接收任务执行
  - ExecutorService(接口)
    - AbstractExectorService(抽象类)
      - ThreadPoolExecutor(实现类)：具体实现线程池功能
    - ScheduledExecutorService(接口)：具有延时和周期执行的ExecutorService
      - ScheduledThreadPoolExecutor(实现类)

Executors：静态工厂类，通过工厂方法提供一些线程池对象ThreadPoolExecutor和ScheduledThreadPoolExecutor；

### 生命周期管理：

线程池使用一个AutomicInteger变量来维护两个状态：运行状态(runState)和线程数量（workerCount）;

该变量通过位运算，高三位代表运行状态，后29位代表有效线程数量；使用一个变量存储两个值，避免在决策时，出现不一致情况，不必为了维护两者一致性而占用锁资源；

- RUNNING：能接受新提交的任务，也能执行阻塞队列中的任务；
- SHUTDOWN：关闭状态，不再接受新提交任务，能执行阻塞队列中的任务；(shutdown())
- STOP：不能接受新任务，也不能执行阻塞队列中已保存的任务，会中断正在处理任务的线程；(shoutdownnow())
- TIDYING：所有任务终止，workerCount = 0；
- TERMINATED: terminated()方法执行后进入该状态;

### 任务执行机制

#### 任务调度：

所有任务调度都是由execute方法完成：检查线程池的运行状态，运行线程数，运行策略，进而决定后边的执行流程，是直接申请线程执行，或缓冲到队列中，或是直接拒绝任务；

执行过程：
- workerCount \< corePoolSize, 创建并启动一个线程执行该任务（放入到workers中）；
- workerCount >= corePoolSize,阻塞队列未满，将任务放入阻塞队列；
- workerCount >= corePoolSize && workerCount \< maxmumPoolSize，且阻塞队列已满，则直接创建线程执行提交任务；
- workerCount >= maxmumPoolSize，且阻塞队列已满，则根据拒绝策略处理该任务；
- 如果阻塞队列未满，则继续加入到阻塞队列中等待工作线程获取任务执行；

### Java线程池提交任务方法？

- execute方法：接收一个Runnable对象实例，无返回值;
- submit方法：接收Runnable或Callable对象实例，返回一个Future对象，Future对象可以用调用isDone判断是否结束，也可以用get方法获取执行结果（如果未结束会阻塞）；


